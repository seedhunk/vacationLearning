# 一.卷积神经网络CNN

## 1.CNN的核心定位与应用场景

卷积神经网络（Convolutional Neural Network, CNN）是深度学习中专门针对**网格结构数据**（如图片的像素网格、语音的时间序列网格）设计的模型，尤其在**图像处理领域**表现突出（如图像分类、目标检测、人脸识别等）。其核心优势在于：通过局部特征提取和参数共享，高效处理高维度网格数据，减少计算量。

------



## 2.CNN的核心原理与关键操作

### 卷积操作（Convolution）

- **核心思想**：模拟人类视觉系统对局部特征的感知（如先识别边缘、纹理，再组合成复杂物体）。

- 具体过程：

  - 使用**卷积核（Kernel/Filter）**（如 3×3 的矩阵）在输入数据（如图像的像素矩阵）上滑动，通过元素相乘再求和，得到局部区域的特征值（特征映射，Feature Map）。

  ![image-20250725201432493](C:\Users\bri\AppData\Roaming\Typora\typora-user-images\image-20250725201432493.png)

  ![image-20250725202529083](C:\Users\bri\AppData\Roaming\Typora\typora-user-images\image-20250725202529083.png)

  - 卷积核的大小决定了 “局部感知” 的范围，例如 3×3 的卷积核关注 3×3 的像素区域。

- 关键特性：

  - **参数共享**：同一卷积核在整个输入数据上重复使用，大幅减少参数数量（区别于全连接网络的每个神经元单独参数）。

    ![image-20250725201717787](C:\Users\bri\AppData\Roaming\Typora\typora-user-images\image-20250725201717787.png)

  - **局部连接**：每个输出神经元仅与输入数据的局部区域相连，符合 “局部特征重要性” 原则。

### 池化操作（Pooling）

- **核心作用**：对卷积后的特征映射进行**降维**，减少计算量，同时增强模型对输入微小变化的鲁棒性（如平移不变性）。

- 常见类型：

  - **最大池化（Max Pooling）**：取局部区域的最大值作为输出（保留最显著特征，如边缘强度）。

  ![image-20250725203053882](C:\Users\bri\AppData\Roaming\Typora\typora-user-images\image-20250725203053882.png)

  - **平均池化（Average Pooling）**：取局部区域的平均值作为输出（平滑特征，减少噪声）。

- **操作示例**：对 2×2 的区域进行池化，将特征图尺寸从 4×4 压缩为 2×2。

### CNN 的典型结构

通常由多个 “卷积层 + 池化层” 堆叠，最后连接全连接层和输出层

![image-20250725203118812](C:\Users\bri\AppData\Roaming\Typora\typora-user-images\image-20250725203118812.png)

1. **输入层**：接收原始数据（如图像的 RGB 像素值，尺寸为 H×W×C，其中 C 为通道数）。

   ![image-20250725202019805](C:\Users\bri\AppData\Roaming\Typora\typora-user-images\image-20250725202019805.png)

2. **卷积层**：通过多个卷积核提取不同局部特征（输出多通道特征映射）。

   ![image-20250725202002558](C:\Users\bri\AppData\Roaming\Typora\typora-user-images\image-20250725202002558.png)

3. **池化层**：对每个通道的特征映射进行降维。

4. **全连接层**：将高维特征映射 flatten 为一维向量，进行分类或回归计算。

5. **输出层**：根据任务输出结果（如分类任务的概率分布）。

![image-20250725203250214](C:\Users\bri\AppData\Roaming\Typora\typora-user-images\image-20250725203250214.png)

------



# 二.循环神经网络RNN

循环神经网络（Recurrent Neural Network，简称 RNN）是一种专门用于处理**序列数据**的神经网络模型，其核心特点是能够利用数据中的时序信息，通过 “记忆” 过去的输入来影响当前的输出，在自然语言处理、语音识别、时间序列预测等领域有着广泛应用。

**可以理解为有记忆力的神经网络**

------



## 1.RNN的核心思想：处理序列数据的需求

在现实世界中，许多数据具有**时序相关性**（即数据的含义与出现的顺序相关），例如：

- 文本：一句话中每个词的含义依赖于前后文（如 “苹果” 可能指水果，也可能指公司，需结合语境判断）；
- 语音：一段语音的识别需要依赖前后的发音；
- 时间序列：股票价格、气温变化等数据的未来趋势与历史数据相关。

传统的神经网络（如全连接网络、CNN）处理数据时，假设输入是独立的，无法捕捉这种时序关系。而 RNN 通过在网络中引入**循环结构**，让神经元的输出可以反馈到输入端，从而 “记住” 之前的信息，实现对序列数据的建模。

------



## 2.RNN 的基本结构与工作原理

### 基本单元：循环神经元

RNN 的核心是**循环神经元**（或称为 “隐藏状态单元”），其结构可简化为：

- 输入：当前时刻的输入数据 *x**t* 和上一时刻的隐藏状态 *h**t*−1；
- 输出：当前时刻的隐藏状态 *h**t* 和可选的输出 *y**t*。

![image-20250726130840225](C:\Users\bri\AppData\Roaming\Typora\typora-user-images\image-20250726130840225.png)

其中，隐藏状态 *h**t* 是 RNN 的 “记忆载体”，计算公式为：*h**t*=*f*(*W**x**h**x**t*+*W**hh**h**t*−1+*b**h*)
（*W**x**h*​ 是输入到隐藏层的权重，*W**hh*​ 是隐藏层到自身的权重，*b**h*​ 是偏置，*f* 是非线性激活函数，如 tanh、ReLU 等）

输出 *y**t* 则由当前隐藏状态计算得到：*y**t*=*g*(*W**h**y**h**t*+*b**y*)
（*W**h**y*​ 是隐藏层到输出层的权重，*b**y*​ 是偏置，*g* 是输出激活函数，如 softmax 用于分类）

### 循环结构的展开

为了更直观理解，可将 RNN 按时间步 “展开”：

- 对于一个长度为 *T* 的序列 (*x*1,*x*2,...,*x**T*)，网络会按时间步依次处理每个输入 *x**t*；
- 每个时间步共享相同的权重参数（*W**x**h*,*W**hh*,*W**h**y*），这意味着网络用同一套规则处理不同时刻的输入，大幅减少了参数数量。
- ![image-20250726130823033](C:\Users\bri\AppData\Roaming\Typora\typora-user-images\image-20250726130823033.png)

------



## 3.RNN 的局限性：长程依赖问题

虽然 RNN 理论上能 “记住” 长期信息，但在实际应用中存在**长程依赖问题**：当序列过长时，早期信息在传递过程中会逐渐衰减或被淹没，导致网络无法有效捕捉远距离的时序关系。

这一问题的本质是**梯度消失或梯度爆炸**：在反向传播计算梯度时，由于权重参数 *W**hh* 会被反复相乘，当序列较长时，梯度可能变得极小（消失）或极大（爆炸），导致模型难以训练。

------



## 4.RNN 的改进模型

为解决长程依赖问题，研究者提出了多种改进模型，其中最经典的是：

### LSTM（长短期记忆网络，Long Short-Term Memory）

LSTM 通过设计**门控机制**（输入门、遗忘门、输出门）来控制信息的流入、遗忘和输出，有效缓解了梯度消失问题，能够记住更长序列的关键信息。

![image-20250726131209744](C:\Users\bri\AppData\Roaming\Typora\typora-user-images\image-20250726131209744.png)

![image-20250726131635034](C:\Users\bri\AppData\Roaming\Typora\typora-user-images\image-20250726131635034.png)



### GRU（门控循环单元，Gated Recurrent Unit）

GRU 是 LSTM 的简化版本，合并了部分门控机制，减少了参数数量，训练速度更快，在许多场景下性能接近 LSTM。



------



## 5.RNN 的典型应用场景

- **自然语言处理（NLP）**：文本生成（如写诗、机器翻译）、情感分析、命名实体识别、语言模型等；
- **语音处理**：语音识别（将语音转为文本）、语音合成（将文本转为语音）；
- **时间序列预测**：股票价格预测、天气预报、设备故障预警等；
- **视频分析**：结合时序信息分析视频帧序列（如动作识别）。